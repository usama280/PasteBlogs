{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MNIST Classifier Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#hide\n",
    "!pip install -Uqq fastbook\n",
    "import fastbook\n",
    "fastbook.setup_book()\n",
    "\n",
    "#hide\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "\n",
    "matplotlib.rc('image', cmap='Greys')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting data and viewing path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#2) [Path('/storage/data/mnist_png/training'),Path('/storage/data/mnist_png/testing')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6742) [Path('/storage/data/mnist_png/training/1/42690.png'),Path('/storage/data/mnist_png/training/1/49817.png'),Path('/storage/data/mnist_png/training/1/12078.png'),Path('/storage/data/mnist_png/training/1/5862.png'),Path('/storage/data/mnist_png/training/1/36368.png'),Path('/storage/data/mnist_png/training/1/57223.png'),Path('/storage/data/mnist_png/training/1/37725.png'),Path('/storage/data/mnist_png/training/1/54103.png'),Path('/storage/data/mnist_png/training/1/29986.png'),Path('/storage/data/mnist_png/training/1/18207.png')...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/\"training/1\").ls()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### This is what the data looks like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAAAmUlEQVR4nGNgGFigcGUVbknPP3/mcOGS3PDnz19lZAEmJLYmAwNDCC6dN//8OSeCSycDA8OhN7gkZ6IbhSx5nYHBHrexjIwG/LgcxDX1z19fXJIMqn/+7uPGI/nHHafWif//3sQpKfL3z3Wckgwv/nz0wymZ++fPPtxab/39ewCn3vV//vz9ZIdDUnQLPu+o/vnbII/bWpoDAGBUNW+XUq+AAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28 at 0x7F864466AB20>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = (path/\"training/1\").ls()\n",
    "t_1 = Image.open(t[0])\n",
    "t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 72x72 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "show_image(tensor(t_1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data appropriately"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#function used to load data appropriatly\n",
    "def load_data(folder):\n",
    "    dataList = []\n",
    "    labelList = []\n",
    "    for num in range(10):\n",
    "        data_path = (path/folder/f'{num}').ls().sorted() #getting path\n",
    "        \n",
    "        stackedData = torch.stack([tensor(Image.open(o)) for o in data_path]) #Open each image and stack them\n",
    "        stackedData = stackedData.float()/255.0 #squishing between 0-1\n",
    "        \n",
    "        dataList.append(stackedData) #adding to dataList\n",
    "        labelList.extend([num]*len(data_path))#extending labelList\n",
    "    \n",
    "    #Convert so that each image data is in each row\n",
    "    train_x = torch.cat(dataList).view(-1, 28*28) \n",
    "    train_y = tensor(labelList)\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "train_x, train_y = load_data(\"training\")\n",
    "test_x, test_y = load_data(\"testing\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating dataloaders (Minibatches)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dset = list(zip(train_x,train_y))\n",
    "valid_dset = list(zip(test_x,test_y))\n",
    "\n",
    "dl_train = DataLoader(train_dset, batch_size=256)\n",
    "dl_test = DataLoader(valid_dset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Below is the functions we need to train and test the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_grad(xb, yb, model):\n",
    "    preds = model(xb)\n",
    "    loss = F.cross_entropy(preds, yb) \n",
    "    loss.backward()\n",
    "\n",
    "def train_epoch(model):\n",
    "    for xb,yb in dl_train:\n",
    "        calc_grad(xb, yb, model)\n",
    "        \n",
    "        for p in params: \n",
    "            p.data -= p.grad.data * lr\n",
    "            p.grad.zero_()\n",
    "\n",
    "def batch_accuracy(xb, yb):\n",
    "    pred = xb.softmax(1)\n",
    "    return batch_accuracy_helper(pred, yb)/float(yb.size(0))\n",
    "\n",
    "def batch_accuracy_helper(preds, yb):\n",
    "    return preds.argmax(dim=1).eq(yb).sum().float()\n",
    "\n",
    "def validate_epoch(model):\n",
    "    accs = [batch_accuracy(model(xb), yb) for xb,yb in dl_test]\n",
    "    return round(torch.stack(accs).mean().item(), 4)\n",
    "\n",
    "def linear_layer(xb):\n",
    "    return xb@w + b\n",
    "\n",
    "def init_params(x, var=1.0): \n",
    "    return (torch.randn(x)*var).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Begin by initializing parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "7aDM5v7oF3fO"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([784, 10]), torch.Size([10]))"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lr = 1.\n",
    "w = init_params((28*28,10))\n",
    "b = init_params(10)\n",
    "params = w, b\n",
    "\n",
    "w.shape, b.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Now lets see if our loss improves for 1 epoch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1534"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "validate_epoch(linear_layer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.1814"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_epoch(linear_layer)\n",
    "validate_epoch(linear_layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## It improved, so now lets train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.255 0.3079 0.3501 0.3783 0.4011 0.4184 0.4319 0.442 0.4507 0.4583 0.4647 0.4711 0.4758 0.4803 0.4833 0.4862 0.488 0.4887 0.4906 0.4925 "
     ]
    }
   ],
   "source": [
    "def train_model(model, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(model)\n",
    "        print(validate_epoch(model), end=' ')\n",
    "        \n",
    "train_model(linear_layer, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We can do all of the above very easily by using FastAI toolkit\n",
    "### Additionally, I will also add some nonlinearity this time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>1.460385</td>\n",
       "      <td>3.105183</td>\n",
       "      <td>0.100900</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.930706</td>\n",
       "      <td>2.921132</td>\n",
       "      <td>0.101200</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.712777</td>\n",
       "      <td>2.385295</td>\n",
       "      <td>0.188500</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.599163</td>\n",
       "      <td>2.020884</td>\n",
       "      <td>0.324600</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.531909</td>\n",
       "      <td>1.787350</td>\n",
       "      <td>0.385900</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.485915</td>\n",
       "      <td>1.628456</td>\n",
       "      <td>0.423500</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.451067</td>\n",
       "      <td>1.514974</td>\n",
       "      <td>0.450500</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.423412</td>\n",
       "      <td>1.429631</td>\n",
       "      <td>0.472800</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.400912</td>\n",
       "      <td>1.362436</td>\n",
       "      <td>0.490200</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.382621</td>\n",
       "      <td>1.307440</td>\n",
       "      <td>0.505100</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0.367557</td>\n",
       "      <td>1.261222</td>\n",
       "      <td>0.519900</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0.355110</td>\n",
       "      <td>1.221475</td>\n",
       "      <td>0.534200</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0.344696</td>\n",
       "      <td>1.186626</td>\n",
       "      <td>0.548400</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0.335849</td>\n",
       "      <td>1.156045</td>\n",
       "      <td>0.562100</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>0.328118</td>\n",
       "      <td>1.129085</td>\n",
       "      <td>0.574200</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>15</td>\n",
       "      <td>0.321477</td>\n",
       "      <td>1.104802</td>\n",
       "      <td>0.585800</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>16</td>\n",
       "      <td>0.315400</td>\n",
       "      <td>1.083139</td>\n",
       "      <td>0.597400</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>17</td>\n",
       "      <td>0.310001</td>\n",
       "      <td>1.063582</td>\n",
       "      <td>0.604800</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>18</td>\n",
       "      <td>0.304906</td>\n",
       "      <td>1.045692</td>\n",
       "      <td>0.611600</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>19</td>\n",
       "      <td>0.300314</td>\n",
       "      <td>1.028769</td>\n",
       "      <td>0.617700</td>\n",
       "      <td>00:01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dls = DataLoaders(dl_train, dl_test)\n",
    "\n",
    "simple_net = nn.Sequential(\n",
    "    nn.Linear(28*28,30), #30 neurons\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(30, 10) # 30neurons into 10 output neurons (10 classes)\n",
    ")\n",
    "\n",
    "learn = Learner(dls, simple_net, opt_func=SGD,\n",
    "                loss_func=F.cross_entropy, metrics=accuracy)\n",
    "\n",
    "learn.fit(20, .01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### So it seems that adding nonlinearity increased the accuracy by 10%!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
