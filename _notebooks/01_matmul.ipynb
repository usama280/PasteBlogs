{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Matrix multiplication from foundations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *foundations* we'll assume throughout this course are:\n",
    "\n",
    "- Python\n",
    "- Python modules (non-DL)\n",
    "- pytorch indexable tensor, and tensor creation (including RNGs - random number generators)\n",
    "- fastai.datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from exp.nb_00 import *\n",
    "import operator\n",
    "\n",
    "def test(a,b,cmp,cname=None):\n",
    "    if cname is None: cname=cmp.__name__\n",
    "    assert cmp(a,b),f\"{cname}:\\n{a}\\n{b}\"\n",
    "\n",
    "def test_eq(a,b): test(a,b,operator.eq,'==')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_eq(TEST,'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To run tests in console:\n",
    "# ! python run_notebook.py 01_matmul.ipynb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "from pathlib import Path\n",
    "from IPython.core.debugger import set_trace\n",
    "import pickle, gzip, math, torch, matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "from torch import tensor\n",
    "\n",
    "from fastai.vision.all import *\n",
    "from fastbook import *\n",
    "MNIST_URL='http://deeplearning.net/data/mnist/mnist.pkl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Path('/storage/data/mnist_png')"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#10) [Path('/storage/data/mnist_png/training/8'),Path('/storage/data/mnist_png/training/3'),Path('/storage/data/mnist_png/training/9'),Path('/storage/data/mnist_png/training/2'),Path('/storage/data/mnist_png/training/4'),Path('/storage/data/mnist_png/training/1'),Path('/storage/data/mnist_png/training/0'),Path('/storage/data/mnist_png/training/5'),Path('/storage/data/mnist_png/training/7'),Path('/storage/data/mnist_png/training/6')]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(path/'training').ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function used to load data appropriatly\n",
    "def load_data(folder):\n",
    "    dataList = []\n",
    "    labelList = []\n",
    "    for num in range(10):\n",
    "        data_path = (path/folder/f'{num}').ls().sorted() #getting path\n",
    "        \n",
    "        stackedData = torch.stack([tensor(Image.open(o)) for o in data_path]) #Open each image and stack them\n",
    "        stackedData = stackedData.float()/255.0 #squishing between 0-1\n",
    "        \n",
    "        dataList.append(stackedData) #adding to dataList\n",
    "        labelList.extend([num]*len(data_path))#extending labelList\n",
    "    \n",
    "    #Convert so that each image data is in each row\n",
    "    train_x = torch.cat(dataList).view(-1, 28*28) \n",
    "    train_y = tensor(labelList)\n",
    "    \n",
    "    return train_x, train_y\n",
    "\n",
    "x_train, y_train = load_data(\"training\")\n",
    "x_valid, y_valid = load_data(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         ...,\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "         [0., 0., 0.,  ..., 0., 0., 0.]]),\n",
       " torch.Size([60000, 784]),\n",
       " tensor([0, 0, 0,  ..., 9, 9, 9]),\n",
       " torch.Size([60000]),\n",
       " tensor(0),\n",
       " tensor(9))"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n,c = x_train.shape\n",
    "x_train, x_train.shape, y_train, y_train.shape, y_train.min(), y_train.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Checking if everything is correct\n",
    "assert n==y_train.shape[0]==60000\n",
    "test_eq(c,28*28)\n",
    "test_eq(y_train.min(),0)\n",
    "test_eq(y_train.max(),9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "mpl.rcParams['image.cmap'] = 'gray'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = x_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'torch.FloatTensor'"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "img.view(28,28).type()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(img.view((28,28)));"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initial python model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "weights = torch.randn(784,10) #28*28 img size, output is 10 classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "bias = torch.zeros(10) #bias for each class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matrix multiplication"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our matmul function\n",
    "def matmul(a,b):\n",
    "    ar,ac = a.shape # n_rows * n_cols\n",
    "    br,bc = b.shape\n",
    "    assert ac==br #must match\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            for k in range(ac): # or br\n",
    "                c[i,j] += a[i,k] * b[k,j]\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "m1 = x_valid[:5]\n",
    "m2 = weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape,m2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.09 s, sys: 0 ns, total: 1.09 s\n",
      "Wall time: 1.09 s\n"
     ]
    }
   ],
   "source": [
    "%time t1=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is kinda slow. It took 1sec to do 5 images, but we have 60k images. Let's see if we can speed this up!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 10])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60000"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidebar: Elementwise ops"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Operators (+,-,\\*,/,>,<,==) are usually element-wise.\n",
    "\n",
    "Examples of element-wise operations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([10.,  6., -4.]), tensor([2., 8., 7.]))"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = tensor([10., 6, -4])\n",
    "b = tensor([2., 8, 7])\n",
    "a,b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([12., 14.,  3.])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.6667)"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(a < b).float().mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = tensor([[1., 2, 3], [4,5,6], [7,8,9]]); m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Frobenius norm:\n",
    "\n",
    "$$\\| A \\|_F = \\left( \\sum_{i,j=1}^n | a_{ij} |^2 \\right)^{1/2}$$\n",
    "\n",
    "*Hint*: you don't normally need to write equations in LaTeX yourself, instead, you can click 'edit' in Wikipedia and copy the LaTeX from there (which is what I did for the above equation). Or on arxiv.org, click \"Download: Other formats\" in the top right, then \"Download source\"; rename the downloaded file to end in `.tgz` if it doesn't already, and you should find the source there, including the equations to copy and paste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(16.8819)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(m*m).sum().sqrt()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elementwise matmul\n",
    "Now let's adjust our matmul func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "        for j in range(bc):\n",
    "            # Any trailing \",:\" can be removed\n",
    "            c[i,j] = (a[i,:] * b[:,j]).sum() \n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.79 ms ± 181 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "178.02"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "890.1/5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "def near(a,b): return torch.allclose(a, b, rtol=1e-3, atol=1e-5)\n",
    "def test_near(a,b): test(a,b,near)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1,matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidebar: Broadcasting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The term **broadcasting** describes how arrays with different shapes are treated during arithmetic operations.  The term broadcasting was first used by Numpy.\n",
    "\n",
    "From the [Numpy Documentation](https://docs.scipy.org/doc/numpy-1.10.0/user/basics.broadcasting.html):\n",
    "\n",
    "    The term broadcasting describes how numpy treats arrays with \n",
    "    different shapes during arithmetic operations. Subject to certain \n",
    "    constraints, the smaller array is “broadcast” across the larger \n",
    "    array so that they have compatible shapes. Broadcasting provides a \n",
    "    means of vectorizing array operations so that looping occurs in C\n",
    "    instead of Python. It does this without making needless copies of \n",
    "    data and usually leads to efficient algorithm implementations.\n",
    "    \n",
    "In addition to the efficiency of broadcasting, it allows developers to write less code, which typically leads to fewer errors.\n",
    "\n",
    "*This section was adapted from [Chapter 4](http://nbviewer.jupyter.org/github/fastai/numerical-linear-algebra/blob/master/nbs/4.%20Compressed%20Sensing%20of%20CT%20Scans%20with%20Robust%20Regression.ipynb#4.-Compressed-Sensing-of-CT-Scans-with-Robust-Regression) of the fast.ai [Computational Linear Algebra](https://github.com/fastai/numerical-linear-algebra) course.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 8 video](https://course19.fast.ai/videos/?lesson=8&t=3110)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Broadcasting with a scalar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10.,  6., -4.])"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True, False])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How are we able to do a > 0?  0 is being **broadcast** to have the same dimensions as a.\n",
    "\n",
    "For instance you can normalize our dataset by subtracting the mean (a scalar) from the entire data set (a matrix) and dividing by the standard deviation (another scalar), using broadcasting.\n",
    "\n",
    "Other examples of broadcasting with a scalar:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11.,  7., -3.])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 2.,  4.,  6.],\n",
       "        [ 8., 10., 12.],\n",
       "        [14., 16., 18.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2*m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Broadcasting a vector to a matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also broadcast a vector to a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([10., 20., 30.])"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = tensor([10.,20,30]); c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3, 3]), torch.Size([3]))"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.shape,c.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c + m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We don't really copy the rows, but it looks as if we did. In fact, the rows are given a *stride* of 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = c.expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.],\n",
       "        [10., 20., 30.],\n",
       "        [10., 20., 30.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> This is what c would look like"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 22., 33.],\n",
       "        [14., 25., 36.],\n",
       "        [17., 28., 39.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 10.0\n",
       " 20.0\n",
       " 30.0\n",
       "[torch.FloatStorage of size 3]"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.storage()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((0, 1), torch.Size([3, 3]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.stride(), t.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can index with the special value [None] or use `unsqueeze()` to convert a 1-dimensional array into a 2-dimensional array (although one of those dimensions has value 1)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.unsqueeze(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> Notice that the shape has changed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 2., 3.],\n",
       "        [4., 5., 6.],\n",
       "        [7., 8., 9.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c.unsqueeze(0).shape,c.unsqueeze(1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([3]), torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c.shape, c[None].shape,c[:,None].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can always skip trailling ':'s. And '...' means '*all preceding dimensions*'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 3]), torch.Size([3, 1]))"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None].shape,c[...,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [20., 20., 20.],\n",
       "        [30., 30., 30.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None].expand_as(m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[11., 12., 13.],\n",
       "        [24., 25., 26.],\n",
       "        [37., 38., 39.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m + c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Sidebar "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Matmul with broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matmul(a,b):\n",
    "    ar,ac = a.shape\n",
    "    br,bc = b.shape\n",
    "    assert ac==br\n",
    "    c = torch.zeros(ar, bc)\n",
    "    for i in range(ar):\n",
    "#       c[i,j] = (a[i,:]          * b[:,j]).sum() # previous\n",
    "        c[i]   = (a[i].unsqueeze(-1) * b).sum(dim=0)\n",
    "    return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "248 µs ± 24 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3194.945848375451"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "885000/277"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sidebar: Broadcasting Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 20., 30.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 3])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10.],\n",
       "        [20.],\n",
       "        [30.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 1])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[:,None].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[100., 200., 300.],\n",
       "        [200., 400., 600.],\n",
       "        [300., 600., 900.]])"
      ]
     },
     "execution_count": null,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None,:] * c[:,None]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[False,  True,  True],\n",
       "        [False, False,  True],\n",
       "        [False, False, False]])"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c[None] > c[:,None]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## End Sidebar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When operating on two arrays/tensors, Numpy/PyTorch compares their shapes element-wise. It starts with the **trailing dimensions**, and works its way forward. Two dimensions are **compatible** when\n",
    "\n",
    "- they are equal, or\n",
    "- one of them is 1, in which case that dimension is broadcasted to make it the same size\n",
    "\n",
    "Arrays do not need to have the same number of dimensions. For example, if you have a `256*256*3` array of RGB values, and you want to scale each color in the image by a different value, you can multiply the image by a one-dimensional array with 3 values. Lining up the sizes of the trailing axes of these arrays according to the broadcast rules, shows that they are compatible:\n",
    "\n",
    "    Image  (3d array): 256 x 256 x 3\n",
    "    Scale  (1d array):             3\n",
    "    Result (3d array): 256 x 256 x 3\n",
    "\n",
    "The [numpy documentation](https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html#general-broadcasting-rules) includes several examples of what dimensions can and can not be broadcast together."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Einstein summation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Einstein summation (`einsum`) is a compact representation for combining products and sums in a general way. From the numpy docs:\n",
    "\n",
    "\"The subscripts string is a comma-separated list of subscript labels, where each label refers to a dimension of the corresponding operand. Whenever a label is repeated it is summed, so `np.einsum('i,i', a, b)` is equivalent to `np.inner(a,b)`. If a label appears only once, it is not summed, so `np.einsum('i', a)` produces a view of a with no changes.\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Jump_to lesson 8 video](https://course19.fast.ai/videos/?lesson=8&t=4280)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c[i,j] += a[i,k] * b[k,j] Inner most loop\n",
    "# c[i,j] = (a[i,:] * b[:,j]).sum() Switched out for this\n",
    "def matmul(a,b): return torch.einsum('ik,kj->ij', a, b) #If you wanted batch wise, do: bik,bkj->bij"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The slowest run took 9.39 times longer than the fastest. This could mean that an intermediate result is being cached.\n",
      "122 µs ± 153 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 _=matmul(m1, m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16090.90909090909"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "885000/55"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, matmul(m1, m2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pytorch op"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use pytorch's function or operator directly for matrix multiplication."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "11 µs ± 5.25 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit -n 10 t2 = m1.matmul(m2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "49166.666666666664"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# time comparison vs pure python:\n",
    "885000/18"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "t2 = m1@m2 #can also do @ = matmul"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_near(t1, t2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([5, 784]), torch.Size([784, 10]))"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m1.shape,m2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python: can't open file 'notebook2script.py': [Errno 2] No such file or directory\r\n"
     ]
    }
   ],
   "source": [
    "!python notebook2script.py 01_matmul.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
