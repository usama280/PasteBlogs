{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.vision.all import * \n",
    "from torch import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from exp.nb_05b import *\n",
    "torch.set_num_threads(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(folder):\n",
    "    dataList = []\n",
    "    labelList = []\n",
    "    for num in range(10):\n",
    "        data_path = (path/folder/f'{num}').ls().sorted() #getting path\n",
    "        \n",
    "        stackedData = torch.stack([tensor(Image.open(o)) for o in data_path]) #Open each image and stack them\n",
    "        stackedData = stackedData.float()/255.0 #squishing between 0-1\n",
    "        \n",
    "        dataList.append(stackedData) #adding to dataList\n",
    "        labelList.extend([num]*len(data_path))#extending labelList\n",
    "    \n",
    "    #Convert so that each image data is in each row\n",
    "    train_x = torch.cat(dataList).view(-1, 28*28) \n",
    "    train_y = tensor(labelList)\n",
    "    \n",
    "    return train_x, train_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = untar_data(URLs.MNIST)\n",
    "path\n",
    "\n",
    "x_train, y_train = load_data(\"training\")\n",
    "x_valid, y_valid = load_data(\"testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize(x, m, s): return (x-m)/s\n",
    "\n",
    "def normalize_to(train, valid):\n",
    "    m,s = train.mean(),train.std()\n",
    "    \n",
    "    return normalize(train, m, s), normalize(valid, m, s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train,x_valid = normalize_to(x_train,x_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor(-1.4117e-09), tensor(1.0000))"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.mean(),x_train.std()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_train = DataLoader(list(zip(x_train, y_train)), 64, shuffle=True, drop_last=True) \n",
    "dls_test = DataLoader(list(zip(x_valid, y_valid)), 128, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dls = DataLoaders(dls_train, dls_test)\n",
    "dls = DataBunch(dls_train, dls_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "#export\n",
    "class Lambda(nn.Module):\n",
    "    def __init__(self, func):\n",
    "        super().__init__()\n",
    "        self.func = func\n",
    "\n",
    "    def forward(self, x): return self.func(x)\n",
    "\n",
    "def flatten(x):      return x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mnist_resize(x): return x.view(-1, 1, 28, 28) #1 channel 28*28"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cnn_model(data):\n",
    "    return nn.Sequential(\n",
    "        Lambda(mnist_resize),\n",
    "              #inp_c,out_c,filter\n",
    "        nn.Conv2d( 1, 8, 5, padding=2,stride=2), nn.ReLU(), #14x14\n",
    "        nn.Conv2d( 8,16, 3, padding=1,stride=2), nn.ReLU(), # 7x7\n",
    "        nn.Conv2d(16,32, 3, padding=1,stride=2), nn.ReLU(), # 4x4\n",
    "        nn.Conv2d(32,32, 3, padding=1,stride=2), nn.ReLU(), # 2x2\n",
    "        nn.AdaptiveAvgPool2d(1),\n",
    "        Lambda(flatten),\n",
    "        nn.Linear(32,10)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = get_cnn_model(dls)\n",
    "opt = optim.SGD(model.parameters(), lr=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Learner():\n",
    "    def __init__(self, model, opt, loss_func, data):\n",
    "        self.model,self.opt,self.loss_func,self.data = model,opt,loss_func,data\n",
    "\n",
    "learn = Learner(model, opt, loss_func, dls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "cbfs = [Recorder, partial(AvgStatsCallback,accuracy), partial(ParamScheduler,'lr', sched_lin(1., 0.2))]\n",
    "run = Runner(cb_funcs=cbfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train: [2.758722881370064, tensor(0.1088)]\n",
      "valid: [2.30245, tensor(0.1135)]\n"
     ]
    }
   ],
   "source": [
    "run.fit(1, learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lets do it using our own fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = get_cnn_model(dls)\n",
    "opt2 = optim.SGD(model.parameters(), lr=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls_train = DataLoader(list(zip(x_train, y_train)), 64, shuffle=True, drop_last=True) \n",
    "dls_test = DataLoader(list(zip(x_valid, y_valid)), 128, shuffle=False) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def accuracy(preds, yb):\n",
    "    return (torch.argmax(preds, dim=1) == yb).float().mean()\n",
    "\n",
    "def fit(epochs):\n",
    "    for i in range(epochs):\n",
    "        model2.train()\n",
    "        \n",
    "        for xb,yb in dls_train:\n",
    "            pred = model2(xb)\n",
    "            loss = F.cross_entropy(pred, yb)\n",
    "            loss.backward()\n",
    "            \n",
    "            opt2.step()\n",
    "            opt2.zero_grad()\n",
    "            \n",
    "        \n",
    "        model2.eval()\n",
    "        with torch.no_grad():\n",
    "            loss,acc = 0.0,0.0\n",
    "            \n",
    "            for xb,yb in dls_test:\n",
    "                pred = model2(xb)\n",
    "                \n",
    "                loss += F.cross_entropy(pred, yb)\n",
    "                acc += accuracy(pred, yb)\n",
    "                \n",
    "        nv = len(dls_test)\n",
    "        print(i, loss/nv, acc/nv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 tensor(2.3082) tensor(0.0804)\n"
     ]
    }
   ],
   "source": [
    "fit(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
